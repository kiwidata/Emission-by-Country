{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046ae5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15a359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import and read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"GCB2022v27_MtCO2_flat.csv\")\n",
    "#application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3168172c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting 2000 data, checking the clustering data\n",
    "\n",
    "df_dl_2000 = application_df[(application_df['Year'] >= 1900) & (application_df ['Country'] == 'Global')]\n",
    "df_dl_2000.shape\n",
    "# print(df_dl_2000)\n",
    "#save every country data for 2000\n",
    "#df_deeplearining_2000.to_csv(r'C:\\Users\\Violet.Huang\\Documents\\14_Berkerly bootscamp\\Final_Project\\Group-Project\\Deep learning\\deeplearining_2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2be5637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Total          Coal           Oil          Gas\n",
      "62982   1952.209498   1873.356867     67.309637    11.541600\n",
      "62983   2016.744495   1929.131922     74.750267    12.860640\n",
      "62984   2067.683966   1973.177627     80.808149    13.696032\n",
      "62985   2254.094927   2154.002798     85.561821    14.527760\n",
      "62986   2279.748708   2166.663609     96.083367    15.165234\n",
      "...             ...           ...           ...          ...\n",
      "63099  36096.739280  14506.973810  12242.627940  7144.928128\n",
      "63100  36826.506600  14746.830690  12266.016290  7529.846784\n",
      "63101  37082.558970  14725.978030  12345.653370  7647.528220\n",
      "63102  35264.085730  14174.564010  11191.808550  7556.290283\n",
      "63103  37123.850350  14979.598080  11837.159120  7921.829472\n",
      "\n",
      "[122 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "df_dl_2000_new = df_dl_2000.drop(['Country','ISO 3166-1 alpha-3','Year','Per Capita','Cement','Flaring','Other'], axis=1)\n",
    "#df.drop(['column_nameA', 'column_nameB'], axis=1, inplace=True)\n",
    "print(df_dl_2000_new)\n",
    "# df_deeplearining_2000_new.to_csv(r'C:\\Users\\Violet.Huang\\Documents\\14_Berkerly bootscamp\\Final_Project\\Group-Project\\Deep learning\\deeplearining_2000_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2db7ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = df_dl_2000_new.drop(columns=\"Total\")\n",
    "y = df_dl_2000_new[\"Total\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c2f0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total    122\n",
       "Coal     122\n",
       "Oil      122\n",
       "Gas      122\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "counts = df_dl_2000_new.nunique()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49ce86d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fd8cb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "len(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cd9fc46",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18756\\4283596269.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Add our first Dense layer, including the input layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'keras'"
     ]
    }
   ],
   "source": [
    "# Add our first Dense layer, including the input layer\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"relu\", input_dim=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# number_input_features = len(X_train_scaled[0])\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "# nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0644f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bad41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = nn_model.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train, pred_train)))\n",
    "\n",
    "# nn_model.save(\"deeplearning.2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea2fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = nn_model.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca438e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
